# 4. The Shared Database Trap â€“ Breaking the Monolithic Store

#### 1. The Scenario: The "Convenient" Nightmare

In a monolith, having one giant database is great. You have a `Customer` table, an `Order` table, and a `Product` table all living happily together.

* Super Power: You can write a single SQL query to join them all: `SELECT * FROM Orders JOIN Customers...`.
* Safety: You have ACID transactions. If the Order fails, the Inventory update rolls back automatically.

The Anti-Pattern in Microservices:

When organizations start migrating, they often split the code into "Microservices" (Java/Node apps) but keep them all connected to the Same Database.

* The Reality: This is not Microservices. This is a "Distributed Monolith."

#### 2. Why is a Shared Database Dangerous?

You might ask: _"If it works, why change it?"_

1. Tight Coupling (The "Hidden Handshake"):
   * Imagine the Identity Team decides to rename the `user_email` column to `email_address` to clean up their code.
   * They deploy their service. It works fine.
   * Suddenly, the Loan Service (managed by a different team) crashes. Why? Because the Loan Service was reading that same table directly.
   * _Result:_ Teams cannot work independently. They must coordinate every database change.
2. Performance Bottlenecks:
   * Different services have different needs. The "Reporting Service" might run heavy analytics queries that lock the database tables, slowing down the "Checkout Service" which needs millisecond speed.
3. Technology Lock-in:
   * If you share one big SQL DB, _everyone_ must use SQL. You can't let the "Catalog Service" use MongoDB (which might be better for product documents) because it's tied to the shared SQL schema.

#### 3. The Golden Rule: Database-per-Service

The Rule: A microservice's persistent data is private to that service. It is accessible _only_ via that service's API.

* The Order Service cannot write SQL to the Customer Table.
* It must call `GET /customer/{id}` on the Customer Service.

"But does that mean buying 50 Oracle licenses?"

No. "Database-per-Service" is a logical concept, not necessarily physical.

1. Private Tables: Service A owns Tables 1-5. Service B owns Tables 6-10. (Easiest start).
2. Separate Schemas: Service A connects to Schema A. Service B connects to Schema B. (Better isolation).
3. Separate Servers: Totally different physical database servers. (Best for scale).

#### 4. The New Challenge: "Where did my Foreign Keys go?"

This is the hardest part of the migration. In a shared DB, the `Orders` table has a Foreign Key to `Customers`. The database engine enforces integrity.

In Microservices, Foreign Keys do not exist across boundaries.

How do we handle relationships?

Strategy A: Reference by ID (The "Soft Link")

Instead of a database constraint, you just store the ID.

* Order Service DB: Stores `customer_id = "C123"`.
* It trusts that `C123` exists in the Customer Service.
* _Trade-off:_ You lose referential integrity. It is possible to have an order for a customer that was deleted. You must handle this in code (e.g., check validity before creating an order).

Strategy B: API Composition (The "Software Join")

Since you can't JOIN tables, you JOIN in memory.

* Scenario: You need to show a screen with "Order Details + Customer Name".
* Step 1: The frontend (or an aggregator service) calls the Order Service to get the order. It sees `customer_id: "C123"`.
* Step 2: It then calls the Customer Service (`GET /customers/C123`) to get the name "John Doe".
* Step 3: It combines them and sends the response.

#### 5. Concept: Bounded Contexts (DDD)

How do you decide which table belongs to which service? You use Domain-Driven Design (DDD).

The Concept:

Don't model the "Real World." Model the "Business Context."

* Example: "The Book"
  * To the Warehouse Service, a Book is physical dimensions (weight, size, shelf location). It doesn't care about the plot.
  * To the Storefront Service, a Book is a title, author, description, and price. It doesn't care about the shelf weight.

The Mistake: creating one giant Book table with 50 columns.

The Fix:

* Warehouse Service has a `StockItem` table (ID, Weight, Location).
* Storefront Service has a `Product` table (ID, Title, Price).
* They share the same ID, but the data is split based on who uses it.

#### 6. Migration Strategy: How to fix the Monolith

Step 1: Logical Separation (The "Do Not Touch" phase)

* Identify which tables belong to the "Payment Service."
* Change the database permissions so _only_ the Payment Service user can read/write those tables.
* If the "Order Service" breaks because it was reading a Payment table, fix the code to use the Payment API instead.

Step 2: Physical Separation (The Move)

* Once the code is clean (no cross-service SQL), you can physically move the Payment tables to a new database server without breaking anything.

#### 7. Quiz: Check Your Understanding

1. Scenario: You need to delete a user. In the old system, `CASCADE DELETE` removed their orders automatically. What happens now?
   * _Answer: Nothing happens automatically. You must implement a process (like publishing a "UserDeleted" event) so the Order Service can listen and decide what to do with the orphan orders._
2. Scenario: The Analytics team hates this. They say, "I can't run my daily report because the data is in 10 different databases!" What is the solution?
   * _Answer: Do not run reports on live microservice databases. Replicate the data into a Data Warehouse or Data Lake using an ETL process or Event Streams._

# 7. Network Latency

#### 1. The "Function Call" Illusion

In your monolith, calling a function was free.

* Code: `userController.getUser(id)` -> calls `userService.getUser(id)`.
* Cost: In-memory call. Takes nanoseconds.
* Reliability: 100%. If the CPU is on, the call works.

The Microservice Reality:

Developers often copy-paste this logic into microservices, replacing the function call with an HTTP Client.

* Code: `userClient.getUser(id)` -> sends HTTP GET to `192.168.1.50`.
* Cost: Network call. Takes milliseconds (often 20ms - 100ms).
* Reliability: The network is not reliable. Packets get lost. Switches fail.

The "Fallacies of Distributed Computing":

Decades ago, Peter Deutsch at Sun Microsystems listed false assumptions developers make.1 The top two are:

1. The Network is Reliable. (It isn't).
2. Latency is Zero. (It definitely isn't).

If you treat a remote API call like a local function call, you are building a fragile system.

#### 2. The "Chatty" Application Problem

Imagine a "Loan Approval" process. It needs to check Credit, Identity, Employment, and Savings.

The Anti-Pattern (Synchronous Chaining):

1. Loan Service receives a request.
2. Calls Credit Service (Waits 200ms).
3. Calls Identity Service (Waits 100ms).
4. Calls Employment Service (Waits 300ms).
5. Total Time: 600ms + Network Overhead.

If you have a loop (e.g., "For each of the user's 10 bank accounts, get the balance"), you trigger 10 separate network calls.

* Result: The user sees a spinning wheel. The system is "Chatty"â€”spending more time talking on the network than doing work.

#### 3. Solution A: Coarse-Grained APIs (Granularity)

One way to fix latency is to talk less often, but say more when you do.

* Fine-Grained (Bad):
  * `GET /user/123/name`
  * `GET /user/123/email`
  * `GET /user/123/address`
  * _(3 Network calls to get one profile)_
* Coarse-Grained (Good):
  * `GET /user/123/full-profile`
  * _(1 Network call returns a larger JSON with name, email, and address)_

Design Tip: Design your internal APIs based on Intent (what the business needs), not just Data Models (database rows).

#### 4. Solution B: Sync vs. Async Communication

This is the most important architectural decision you will make.

**1. Synchronous (Request/Response)**

* Protocols: REST (HTTP/JSON), gRPC (Protobuf).
* Behavior: The caller waits (blocks) until the answer comes back.
* When to use:
  * User UI: The user clicks "Login." They _must_ wait to know if it succeeded.
  * Reads: Fetching data to display on a screen.

**2. Asynchronous (Fire and Forget)**

* Protocols: Message Queues (Kafka, RabbitMQ, ActiveMQ).
* Behavior: The caller sends a message ("UserCreated") and immediately moves on. The receiver picks it up later.
* When to use:
  * Background Tasks: "Send Welcome Email." (The user doesn't need to wait for the email to arrive to see the "Success" screen).
  * Heavy Processing: "Generate Monthly PDF Statement."
  * Decoupling: Any time the caller doesn't need the answer _right now_.

The "Loan Approval" fix with Async:

1. Loan Service accepts the request: "We received your application. We will email you shortly." (Returns instantly).
2. Loan Service drops a message into a Queue: `NewLoanApplication`.
3. Credit Service, Identity Service, etc., pick up the message in parallel and process it.
4. When done, they notify the user.

<figure><img src="https://encrypted-tbn3.gstatic.com/licensed-image?q=tbn:ANd9GcSVJedkkGmC396qU6BvkAq-ViUf4KO9HzBr3duFihBUL6qrBRCWounfbd2MagiKdtfuyzw6Au6oFyui4LdM8C-UDiEqJDX7xbunc2gwxwXGbCGcYig" alt=""><figcaption></figcaption></figure>

#### 5. Deep Dive: REST vs. gRPC vs. Kafka

| **Feature** | **REST (HTTP 1.1)**                       | **gRPC (HTTP/2)**                                       | **Kafka/RabbitMQ (Async)**            |
| ----------- | ----------------------------------------- | ------------------------------------------------------- | ------------------------------------- |
| Type        | Synchronous                               | Synchronous                                             | Asynchronous                          |
| Data Format | JSON (Human readable, bulky)              | Protobuf (Binary, compressed, fast)                     | Binary/JSON/Avro                      |
| Coupling    | High (Caller needs Receiver to be online) | High (Caller needs Receiver to be online)               | Low (Receiver can be offline)         |
| Use Case    | Public APIs, Web Frontends                | Internal Service-to-Service communication (Low Latency) | Decoupling, Event Driven Architecture |

#### 6. Quiz: Check Your Understanding

1. Scenario: You need to calculate the "Total Net Worth" of a user by summing up balances from 5 different account types (Savings, Checking, Credit, Investment, Loan). These are 5 different services.
   * _Bad Design:_ The Gateway calls Service A, waits, calls Service B, waits... (Sequential).
   * _Better Design:_ The Gateway calls A, B, C, D, E in parallel (Concurrent).
   * _Best Design (if speed is critical):_ Create a "view" database that pre-calculates this total (CQRS), so it's just 1 call.
2. Scenario: A user uploads a 50MB document for KYC (Know Your Customer) verification. This takes 30 seconds to process. Should you use REST or Messaging?
   * _Answer: Messaging (Async). If you keep an HTTP connection open for 30 seconds, it will likely time out or block the browser. Upload the file, return "Processing...", and send an event to a queue to process it in the background._
